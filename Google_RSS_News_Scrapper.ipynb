{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOrbgcQ6A7denMZbTeoRAYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intigration/Python/blob/master/Google_RSS_News_Scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the python dependencies"
      ],
      "metadata": {
        "id": "urLFOuB8rQo2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObHW8dXJrJV2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from xml.dom.minidom import parseString\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the function to fetch the google technology articles."
      ],
      "metadata": {
        "id": "tG0DkdJvrPcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_google_news_result(term, count):\n",
        "    results = []\n",
        "    obj = parseString(\n",
        "        requests.get(\"http://news.google.com/news?q=%s&output=rss\" % term).text\n",
        "    )\n",
        "    items = obj.getElementsByTagName(\"item\")\n",
        "    # print(items)\n",
        "    # Storing the Titles and Links\n",
        "    titles = []\n",
        "    links = []\n",
        "    descriptions = []\n",
        "    for item in items[:count]:\n",
        "        title, link, description = \"\", \"\", \"\"\n",
        "        for node in item.childNodes:\n",
        "            # print(node)\n",
        "            if node.nodeName == \"title\":\n",
        "                title = node.childNodes[0].data\n",
        "            elif node.nodeName == \"description\":\n",
        "                description = node.childNodes[0].data\n",
        "            elif node.nodeName == \"link\":\n",
        "                link = node.childNodes[0].data\n",
        "        titles.append(title)\n",
        "        links.append(link)\n",
        "        descriptions.append(description)\n",
        "\n",
        "    return titles, links, descriptions\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  titleName = input(\"Enter the news title keyword: \")\n",
        "  if titleName=='':\n",
        "    titleName='technology'\n",
        "  else:\n",
        "    # articleCount = int(input(\"Enter the number of article count: \"))\n",
        "    articleCount = 10\n",
        "    titles, links, descriptions = get_google_news_result(titleName, articleCount)\n",
        "    news = {\"title\": titles, \"link\": links, \"description\":descriptions}\n",
        "    print(news)\n",
        "    df = pd.DataFrame(news, columns=[\"title\", \"link\", \"description\"])\n",
        "    df.to_json(\"{}_news_scrapper.json\".format(titleName),orient='records', lines=True)\n"
      ],
      "metadata": {
        "id": "A5AXut-xrPHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}